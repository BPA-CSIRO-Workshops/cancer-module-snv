%----------------------------------------------------------------------------------------
%	MODULE INFORMATION
%----------------------------------------------------------------------------------------

% Define the top matter
\setModuleTitle{Single Nucleotica Variant Call and Annotation}
\setModuleAuthors{%
  Matt Field \mailto{matt.field@anu.edu.au}\\
  Dan Andrews \mailto{dan.andrews@anu.edu.au}\\
  Velimir Gayevskiy \mailto{v.gayevskiy@garvan.org.au} \\
}

\setModuleContributions{%
  Gayle Phillip \mailto{Sonika.Tyagi@agrf.org.au} \\
  Sonika Tyagi \mailto{gkphilip@unimelb.edu.au}% 
}

%----------------------------------------------------------------------------------------
%	MODULE TITLE PAGE
%----------------------------------------------------------------------------------------

\chapter{\moduleTitle}

%----------------------------------------------------------------------------------------

\newpage

%----------------------------------------------------------------------------------------
%	LEARNING OUTCOMES
%----------------------------------------------------------------------------------------

\section{Key Learning Outcomes}

After completing this practical the trainee should be able to:

\begin{itemize}
  \item Prepare raw BAM alignments for variant detection 
  \item Perform QC measures on BAM files
  \item Understand and perform simple variant detection on paired NGS data 
  \item Add annotation information to raw variant calls
  \item Visualise variant calls using IGV
\end{itemize}

%----------------------------------------------------------------------------------------
%	MODULE RESOURCES
%----------------------------------------------------------------------------------------

\section{Resources You'll be Using}

\subsection{Tools Used}

\begin{description}[style=multiline,labelindent=0cm,align=left,leftmargin=1cm]
  \item[SAMTools] \hfill\\
    \url{http://sourceforge.net/projects/samtools/}
  \item[IGV] \hfill\\
    \url{http://www.broadinstitute.org/igv/}
  \item[Genome Analysis Toolkit] \hfill\\
    \url{http://www.broadinstitute.org/gatk/}
  \item[Picard] \hfill\\
    \url{http://picard.sourceforge.net/}
  \item[MuTect] \hfill\\
    \url{http://www.broadinstitute.org/cancer/cga/mutect/}
  \item[Strelka] \hfill\\
    \url{https://sites.google.com/site/strelkasomaticvariantcaller/}
  \item[VarScan2] \hfill\\
    \url{https://github.com/dkoboldt/varscan/}

\end{description}

%------------------------------------------------

\subsection{Sources of Data}

\url{http://sra.dnanexus.com/studies/ERP001071}\\
\url{http://www.ncbi.nlm.nih.gov/pubmed/22194472}

%----------------------------------------------------------------------------------------

\newpage

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\section{Introduction}

This talk is based on Introduction to DNA-Seq processing for cancer data by Mathieu Bourgey, Ph.D  

*https://bitbucket.org/mugqic/muqpic\_pipelines*

The goal of this hands-on session is to present the main steps that are commonly used to process and to analyze cancer sequencing data. We will focus only on whole genome data and provide command lines that allow detecting Single Nucleotide Variants (SNV). This workshop will show you how to launch individual steps of a complete DNA-Seq SNV pipeline using cancer data.

In the second part of the tutorial we will also be using IGV to visualise and manually inspect candidate variant calls.

%----------------------------------------------------------------------------------------
%	THE ENVIRONMENT
%----------------------------------------------------------------------------------------

\section{Prepare the Environment}

We will use a dataset derived from whole genome sequencing of a 33-yr-old lung adenocarcinoma patient, who is a never-smoker and has no familial cancer history.

The data consists of whole genome sequencing of liver metastatic lung cancer (frozen), primary lung cancer (FFPE) and blood tissue of a lung adenocarcinoma patient (AK55).

The BAM alignment files are contained in the subdirectory called \texttt{alignment} and are located in the following subdirectories:

\begin{description}[style=multiline,labelindent=1.5cm,align=left,leftmargin=2.5cm]
  \item[\texttt{normal/normal.sorted.bam} and \texttt{normal/normal.sorted.bam.bai}] \hfill\\
  \item[\texttt{tumor/tumor.sorted.bam} and \texttt{tumor/tumor.sorted.bam.bai}] \hfill\\ 
\end{description}

These files are based on subsetting the whole genomes derived from blood and liver metastases to the first 50Mb of chromosome 4 (with only the first 10Mb of chr4 utilised for particularly computationally intensive steps such as variant calling!). This will allow our analyses to run in a sufficient time during the workshop, but it's worth being aware that these are just 1.25\% of the genome which highlights the length of time and resourced required to perform cancer genomics on full genomes!

\begin{directory\_structure}
The initial structure of your folders should look like this:

\begin{verbatim}
-- raw_reads/            # fastqs from the center (down sampled)
  -- normal/              # The blood sample directory containing fastq's 
  -- tumor/               # The tumour sample directory containing fastq's
-- alignment/	          # bam files 
  -- normal/              # The blood sample directory containing bam files 
  -- tumour/               # The tumour sample directory containing bam files \\
-- ref/                   # Contains reference genome files	     
-- commands.sh            # cheat sheet 
\end{verbatim}


\end{directory\_structure}

\begin{steps}
Open the Terminal and go to the base \texttt{workshopCanberra} working directory:
\begin{lstlisting}
cd ~/workshopCanberra
\end{lstlisting}
\end{steps}

%\reversemarginpar\marginpar{\vskip+0em\hfill\includegraphics[height=1cm]{graphics/warning.png}}
%\textcolor{red}{
\begin{warning}
  All commands entered into the terminal for this tutorial should be from within the
  \textbf{\texttt{workshopCanberra}} directory.
\end{warning}

\begin{steps}
Check that the \texttt{alignment} directory contains the above-mentioned files by typing:
\begin{lstlisting}
ls alignment
\end{lstlisting}
\end{steps}

\begin{steps}
Now we need to set some environment variables to save typing lengthy file paths over and over. Copy and paste the following commands into your terminal.
\begin{lstlisting}
export APP_ROOT=/home/training/Applications/

export PATH=$PATH:$APP_ROOT/IGVTools

export PICARD_PATH=$APP_ROOT/picard-tools/

export SNPEFF_HOME=$APP_ROOT/snpEff/

export GATK_JAR=$APP_ROOT/gatk/GenomeAnalysisTK.jar

export BVATOOLS_JAR=$APP_ROOT/bvatools-1.6/bvatools-1.6-full.jar

export TRIMMOMATIC_JAR=$APP_ROOT/Trimmomatic-0.33/trimmomatic-0.33.jar

export STRELKA_HOME=$APP_ROOT/strelka-1.0.14/

export MUTECT_JAR=$APP_ROOT/mutect-src/mutect-1.1.7.jar

export VARSCAN_JAR=$APP_ROOT/varscan2/VarScan.v2.3.9.jar

export REF=/home/training/workshopCanberra/ref
\end{lstlisting}
\end{steps}


%----------------------------------------------------------------------------------------
%	BAM MANIPULATION
%----------------------------------------------------------------------------------------


\section{BAM Files}

Let's spend some time to explore bam files.

\subsection{Step 1: Exploring BAM files}

\begin{steps}
\begin{lstlisting}
samtools view alignment/normal/normal.sorted.bam | head -n4
\end{lstlisting}
\end{steps}

Here you have examples of alignment results.
A full description of the flags can be found in the SAM specification
\url{http://samtools.sourceforge.net/SAM1.pdf}

Another useful bit of information in the SAM is the CIGAR string.
It's the 6th column in the file. 

This column explains how the alignment was achieved.
 
        M == base aligns \textbf{but doesn't have to be a match.} A SNP will have an M even if it disagrees with the reference.\\
        I == Insertion\\
        D == Deletion\\
        S == soft-clips. These are handy to find un removed adapters, viral insertions, etc.

An in depth explanation of the CIGAR can be found \url{http://genome.sph.umich.edu/wiki/SAM}

The exact details of the cigar string can be found in the SAM spec as well.


We won't go into too much detail at this point since we want to concentrate on cancer specific issues now.


Now, you can try using picards explain flag site to understand what is going on with your reads
\url{http://broadinstitute.github.io/picard/explain-flags.html}

\begin{question} 
There are 3 unique flags, what do they mean? The flag is the second column.
\end{question}
\begin{answer}
\textbf{129:}\\ 
    read paired\\
    second in pair\\ \\
\textbf{113:}\\
    read paired\\
    read reverse strand\\
    mate reverse strand\\
    first in pair\\ \\
\textbf{161:}\\
    read paired\\
    mate reverse strand\\
    second in pair\\
\end{answer}

There are lots of possible different flags, let's look at a few more
\begin{lstlisting}
samtools view alignment/normal/normal.sorted.bam | head -n100
\end{lstlisting}


\begin{question} 
Let's take the last one, which looks properly paired and find it's mate pair. \\
[HINT: Instead of using 'head' what unix command could we pipe the otput to?]
\end{question}
\begin{answer}
\begin{lstlisting}
samtools view alignment/normal/normal.sorted.bam | grep HWI-ST478_0133:4:2205:14675:32513
\end{lstlisting}
\end{answer}

\begin{question} 
Using the cigar string, what can we tell about the alignment of the mate pair?
\end{question}
\begin{answer}
The mate pair has a less convincing alignment with two insertions and soft clipping reported.
\end{answer}

\begin{question} 
How might the alignment information from the original read be used by the aligner?
\end{question}
\begin{answer}
Even though the alignment of the mate pair is questionable the presence of it's properly paired mate helps the aligner in deciding where to put the less-certain read. 
\end{answer}

You can use samtools to filter reads as well.

\begin{question} 
How many reads mapped and unmapped were there? \\
[HINT: Look at the samtools view help menu by typing samtools view without any arguments]
\end{question}
\begin{answer}
\begin{lstlisting}
samtools view -c -f4 alignment/normal/normal.sorted.bam
\end{lstlisting}
77229
\begin{lstlisting}
samtools view -c -F4 alignment/normal/normal.sorted.bam
\end{lstlisting}
22972373
\end{answer}

\subsection{Step 2: Pre-processing: Indel Realignment}
The first step for this is to realign around indels and snp dense regions.\\
The Genome Analysis toolkit has a tool for this called IndelRealigner. \\
It basically runs in 2 steps: \\
   1. Find the targets \\
   2. Realign them \\

\begin{lstlisting}
java -Xmx2G  -jar ${GATK_JAR} \
  -T RealignerTargetCreator \
  -R ${REF}/human_g1k_v37.fasta \
  -o alignment/normal/realign.intervals \
  -I alignment/normal/normal.sorted.bam \
  -I alignment/tumuor/tumour.sorted.bam \
  -L ${REF}/human_g1k_v37.intervals

java -Xmx2G -jar ${GATK_JAR} \
  -T IndelRealigner \
  -R ${REF}/human_g1k_v37.fasta \
  -targetIntervals alignment/normal/realign.intervals \
  --nWayOut .realigned.bam \
  -I alignment/normal/normal.sorted.bam \
  -I alignment/tumour/tumour.sorted.bam \
  -L ${REF}/human_g1k_v37.intervals

  mv normal.sorted.realigned.ba* alignment/normal/
  mv tumour.sorted.realigned.ba* alignment/tumour/
\end{lstlisting}


\begin{note}
Explanation of parameters
\begin{description}[style=multiline,labelindent=0cm,align=right,leftmargin=\descriptionlabelspace,rightmargin=1.5cm,font=\ttfamily]
 \item[-I] BAM file(s)
 \item[-T] GATK algorithm to run
 \item[-R] the reference genome used for mapping (b37 from GATK here)
 \item[-jar] Path to GATK jar file
 \item[-L] Genomic intervals to operate on
\end{description}
\end{note}

This will take approximately NN minutes to run... \\

\begin{question} 
Why did we use both normal and tumor together?
\end{question}
\begin{answer}
Because if a region needs realignment, maybe one of the sample in the pair has less reads or was excluded from the target creation. \\
This makes sure the normal and tumor are all in-sync for the somatic calling step. 
\end{answer}

\begin{question} 
How many regions did it think needed cleaning ? 
\end{question}
\begin{answer}
\begin{lstlisting}
wc -l alignment/normal/realign.intervals -> 27300
\end{lstlisting}
\end{answer}

Indel Realigner also makes sure the called deletions are left aligned when there is a microsatellite or homopolymer.

\begin{verbatim}
This
ATCGAAAA-TCG
into
ATCG-AAAATCG

or
ATCGATATATATA--TCG
into
ATCG--ATATATATATCG
\end{verbatim}


\begin{question} 
Why it is important ? 
\end{question}
\begin{answer}
This makes it easier for down stream analysis tools

For NGS analysis, the convention is to left align indels. 

This is only really needed when calling variants with legacy locus-based tools such as samtools or GATK UnifiedGenotyper. Otherwise you will have worse performance and accuracy.

With more sophisticated tools (like GATK HaplotypeCaller) that involve reconstructing haplotypes (eg through reassembly), the problem of multiple valid representations is handled internally and does not need to be corrected explicitly.
\end{answer}

\subsection{Step 3: Pre-processing: Fixmates}

Some read entries don't have their mate information written properly. \\
We use Picard to do this: 

\begin{lstlisting}
java -Xmx2G -jar ${PICARD_PATH}/FixMateInformation.jar \
  VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true SORT_ORDER=coordinate MAX_RECORDS_IN_RAM=500000 \
  INPUT=alignment/normal/normal.sorted.realigned.bam \
  OUTPUT=alignment/normal/normal.matefixed.bam

java -Xmx2G -jar ${PICARD_PATH}/FixMateInformation.jar \
  VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true SORT_ORDER=coordinate MAX_RECORDS_IN_RAM=500000 \
  INPUT=alignment/tumour/tumour.sorted.realigned.bam \
  OUTPUT=alignment/tumour/tumour.matefixed.bam
\end{lstlisting}

\subsection{Step 4: Pre-processing: Mark Duplicates}

\begin{question}
What are duplicate reads ?
\end{question}
\begin{answer}
Different read pairs representing the same initial DNA fragment.
\end{answer}

\begin{question} 
What are they caused by ?
\end{question}
\begin{answer}
PCR reactions (PCR duplicates) \\
Some clusters that are thought of being separate in the flowcell but are the same (optical duplicates)
\end{answer}

\begin{question} 
What are the ways to detect them ?
\end{question}
\begin{answer}
Picard and samtools uses the alignment positions: \\
   - Both 5' ends of both reads need to have the same positions. \\ 
   - Each reads have to be on the same strand as well. \\ \\
Another method is to use a kmer approach: \\
   - take a part of both ends of the fragment \\
   - build a hash table  \\
   - count the similar hits \\ \\
Brute force, compare all the sequences.
\end{answer}

Here we will use picards approach:
\begin{lstlisting}
java -Xmx2G -jar ${PICARD_PATH}/MarkDuplicates.jar \
  REMOVE_DUPLICATES=false CREATE_MD5_FILE=true VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true \
  INPUT=alignment/normal/normal.matefixed.bam \
  OUTPUT=alignment/normal/normal.sorted.dup.bam \
  METRICS_FILE=alignment/normal/normal.sorted.dup.metrics

java -Xmx2G -jar ${PICARD_PATH}/MarkDuplicates.jar \
  REMOVE_DUPLICATES=false CREATE_MD5_FILE=true VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true \
  INPUT=alignment/tumour/tumour.matefixed.bam \
  OUTPUT=alignment/tumour/tumour.sorted.dup.bam \
  METRICS_FILE=alignment/tumour/tumour.sorted.dup.metrics
\end{lstlisting}


We can look in the metrics output to see what happened.

\begin{lstlisting}
less alignment/normal/normal.sorted.dup.metrics
\end{lstlisting}

\begin{question} 
What percent of reads are duplicates?
\end{question}
\begin{answer}
0.46\%
\end{answer}

\begin{question} 
Often, we have multiple libraries and when this occurs separate measures are calculated for each library. Why is this important to do not combine everything ?
\end{question}
\begin{answer}
Each library represents a set of different DNA fragments.

Each library involves different PCR reactions

So PCR duplicates can not occur between fragment of two different libraries.

But similar fragment could be found between libraries when the coverage is high.
\end{answer}


\subsection{Step 4: Pre-processing: Base Quality Recalibration}

\begin{question}
Why do we need to recalibrate base quality scores ?
\end{question}
\begin{answer}
The vendors tend to inflate the values of the bases in the reads.
 
The recalibration tries to lower the scores of some biased motifs for some technologies.
\end{answer}

It runs in 2 steps, \\
1- Build covariates based on context and known snp sites \\
2- Correct the reads based on these metrics

GATK BaseRecalibrator:

\begin{lstlisting}
for i in normal tumour
do
  java -Xmx2G -jar ${GATK_JAR} \
    -T BaseRecalibrator \
    -nct 2 \
    -R ${REF}/human_g1k_v37.fasta \
    -knownSites ${REF}/dbSnp-138_chr4.vcf \
    -L 4:1-10000000 \
    -o alignment/${i}/${i}.sorted.dup.recalibration_report.grp \
    -I alignment/${i}/${i}.sorted.dup.bam

    java -Xmx2G -jar ${GATK_JAR} \
      -T PrintReads \
      -nct 2 \
      -R ${REF}/human_g1k_v37.fasta \
      -BQSR alignment/${i}/${i}.sorted.dup.recalibration_report.grp \
      -o alignment/${i}/${i}.sorted.dup.recal.bam \
      -I alignment/${i}/${i}.sorted.dup.bam
done
\end{lstlisting}

\section{BAM QC}

Once your whole bam is generated, it's always a good thing to check the data again to see if everything makes sense.

\subsection{Step 1: BAM QC: Compute Coverage}
If you have data from a capture kit, you should see how well your targets worked. Both GATK and BVATools have depth of coverage tools. \\
Here we'll use the GATK one
\begin{lstlisting}
# Get Depth
for i in normal tumour
do
  java  -Xmx2G -jar ${GATK_JAR} \
    -T DepthOfCoverage \
    --omitDepthOutputAtEachBase \
    --summaryCoverageThreshold 10 \
    --summaryCoverageThreshold 25 \
    --summaryCoverageThreshold 50 \
    --summaryCoverageThreshold 100 \
    --start 1 --stop 500 --nBins 499 -dt NONE \
    -R ${REF}/human_g1k_v37.fasta \
    -o alignment/${i}/${i}.sorted.dup.recal.coverage \
    -I alignment/${i}/${i}.sorted.dup.recal.bam \
    -L 4:1-10000000
done
\end{lstlisting}
\begin{note}
Explanation of parameters
\begin{description}[style=multiline,labelindent=0cm,align=right,leftmargin=\descriptionlabelspace,rightmargin=1.5cm,font=\ttfamily]
 \item[--omitBaseOutput] Do not output depth of coverage at each base
 \item[--summaryCoverageThreshold] Coverage threshold (in percent) for summarizing statistics
 \item[-dt] down sampling
 \item[-L] Genomic intervals to operate on
\end{description}
\end{note}


Coverage is expected to be ~25x in these project

Look at the coverage:

\begin{lstlisting}
less -S alignment/normal/normal.sorted.dup.recal.coverage.sample_interval_summary
less -S alignment/tumour/tumour.sorted.dup.recal.coverage.sample_interval_summary
\end{lstlisting}

\begin{question}
Is the coverage fit with the expectation ?
\end{question}
\begin{answer}
Yes the mean coverage of the region is 25x:

summaryCoverageThreshold is a useful function to see if your coverage is uniform.
 
Another way is to compare the mean to the median. If both are quite different that means something is wrong in your coverage.
\end{answer}

\subsection{Step 2: BAM QC: Insert Size}
It corresponds to the size of DNA fragments sequenced.

Different from the gap size (= distance between reads) !

These metrics are computed using Picard:

\begin{lstlisting}
# Get insert size
for i in normal tumour
do
  java -Xmx2G -jar ${PICARD_PATH}/CollectInsertSizeMetrics.jar \
    VALIDATION_STRINGENCY=SILENT \
    REFERENCE_SEQUENCE=${REF}/human_g1k_v37.fasta \
    INPUT=alignment/${i}/${i}.sorted.dup.recal.bam \
    OUTPUT=alignment/${i}/${i}.sorted.dup.recal.metric.insertSize.tsv \
    HISTOGRAM_FILE=alignment/${i}/${i}.sorted.dup.recal.metric.insertSize.histo.pdf \
    METRIC_ACCUMULATION_LEVEL=LIBRARY
done
\end{lstlisting}

look at the output

\begin{lstlisting}
less -S alignment/normal/normal.sorted.dup.recal.metric.insertSize.tsv
less -S alignment/tumour/tumour.sorted.dup.recal.metric.insertSize.tsv
\end{lstlisting}

\begin{question}
How do the two libraries compares? 
\end{question}
\begin{answer}
The tumour sample has a larger median insert size than the normal sample (405 vs329) 
\end{answer}

\subsection{Step 3: BAM QC: Alignment metrics}
It tells you if your sample and you reference fit together

For the alignment metrics, samtools flagstat is very fast but with bwa-mem since some reads get broken into pieces, the numbers are a bit confusing. 

We prefer the Picard way of computing metrics:
\begin{lstlisting}
for i in normal tumour
do
  java -Xmx2G -jar ${PICARD_PATH}/CollectAlignmentSummaryMetrics.jar \
    VALIDATION_STRINGENCY=SILENT \
    REFERENCE_SEQUENCE=${REF}/human_g1k_v37.fasta \
    INPUT=alignment/${i}/${i}.sorted.dup.recal.bam \
    OUTPUT=alignment/${i}/${i}.sorted.dup.recal.metric.alignment.tsv \
    METRIC_ACCUMULATION_LEVEL=LIBRARY
done
\end{lstlisting}

explore the results

\begin{lstlisting}
less -S alignment/normal/normal.sorted.dup.recal.metric.alignment.tsv
less -S alignment/tumour/tumour.sorted.dup.recal.metric.alignment.tsv

\end{lstlisting}

\begin{question}
Do you think the sample and the reference genome fit together ?
\end{question}
\begin{answer}
Yes, 99\% of the reads have been aligned \\
Usually, we consider:  \\
   - A good alignment if > 85\% \\
   - Reference assembly issues if [60-85]\% \\
   - Probably a mismatch between sample and ref if < 60 \%
\end{answer}




\newpage

%----------------------------------------------------------------------------------------
%	VISUALISATION
%----------------------------------------------------------------------------------------

\section{Variant Calling}

Most of SNV caller use either a Baysian, a threshold or a t-test approach to do the calling

 Here we will try 3 variant callers.\\
- Varscan 2 \\
- MuTecT \\
- Strelka

Other candidates \\
- Virmid \\
- Somatic sniper

many, MANY others can be found here:
\url{https://www.biostars.org/p/19104/}


In our case, let's create a new work directory to start with (from base directory):

\begin{lstlisting}
mkdir variant_calling
\end{lstlisting}

## varscan 2

VarScan calls somatic variants (SNPs and indels) using a heuristic method and a statistical test based on the number of aligned reads supporting each allele.


Varscan somatic caller expects both a normal and a tumour file in SAMtools pileup format from sequence alignments in binary alignment/map (BAM) format. To build a pileup file, you will need:

- A SAM/BAM file ("myData.bam") that has been sorted using the sort command of SAMtools.
- The reference sequence ("reference.fasta") to which reads were aligned, in FASTA format.
- The SAMtools software package.


\begin{lstlisting}
for i in normal tumour
do
samtools mpileup -L 1000 -B -q 1 \
  -f ${REF}/human_g1k_v37.fasta \
  -r 4:1-10000000 \
  alignment/${i}/${i}.sorted.dup.recal.bam \
  > variant_calling/${i}.mpileup
done

java -Xmx2G -jar ${VARSCAN_JAR} \
somatic variant_calling/normal.mpileup \
variant_calling/tumour.mpileup \
variant_calling/varscan \
--output-vcf 1 \
--strand-filter 1 \
--somatic-p-value 0.001 
\end{lstlisting}

Notes on samtools/bcftools arugments
\begin{verbatim}
Samtools:
	-L 1000 : max per-sample depth for INDEL calling [1000] ; 
	-B : disable BAQ (per-Base Alignment Quality) ; 
	-q 1 : skip alignments with mapQ smaller than 1 ; 
	-g generate genotype likelihoods in BCF format

Bcftools :
	-v output potential variant sites only
	-c SNP calling (force –e : likelihood based analyses)
	-g call genotypes at variant sites
\end{verbatim}

Now let's try a different variant caller, MuTect\\

# Note MuTecT only works with Java 6, 7 will give you an error \\
# if you get "Comparison method violates its general contract! \\
# you used java 7"

\begin{lstlisting}
java -Xmx2G -jar ${MUTECT_JAR} \
  -T MuTect \
  -R ${REF}/human_g1k_v37.fasta \
  -dt NONE -baq OFF --validation_strictness LENIENT -nt 2 \
  --dbsnp ${REF}/dbSnp-138_chr4.vcf \
  --input_file:normal alignment/normal/normal.sorted.dup.recal.bam \
  --input_file:tumor alignment/tumour/tumour.sorted.dup.recal.bam \
  --out variant_calling/mutect.call_stats.txt \
  --coverage_file variant_calling/mutect.wig.txt \
  -pow variant_calling/mutect.power \
  -vcf variant_calling/mutect.vcf \
  -L 4:1-10000000
\end{lstlisting}

And finally let's try Illumina's Strelka

\begin{lstlisting}
cp ${STRELKA_HOME}/etc/strelka_config_bwa_default.ini ./
# Fix ini since we subsampled
sed 's/isSkipDepthFilters =.*/isSkipDepthFilters = 1/g' -i strelka_config_bwa_default.ini

${STRELKA_HOME}/bin/configureStrelkaWorkflow.pl \
  --normal=alignment/normal/normal.sorted.dup.recal.bam \
  --tumor=alignment/tumour/tumour.sorted.dup.recal.bam \
  --ref=${REF}/human_g1k_v37.fasta \
  --config=$(pwd)/strelka_config_bwa_default.ini \
  --output-dir=variant_calling/strelka/

  cd variant_calling/strelka/
  make -j2
  cd ../..

  cp variant_calling/strelka/results/passed.somatic.snvs.vcf variant_calling/strelka.vcf
\end{lstlisting}

Now we have variants from all three methods. Let's compress and index the vcfs for future visualisation.

\begin{lstlisting}
for i in variant_calling/*.vcf;do bgzip -c $i > $i.gz ; tabix -p vcf $i.gz;done
\end{lstlisting}

Let's look at a compressed vcf.

\begin{lstlisting}
zless -S variant_calling/varscan.snp.vcf.gz
\end{lstlisting}

Details on the spec can be found here:
\url{http://vcftools.sourceforge.net/specs.html}

Fields vary from caller to caller.
 
Some values are are almost always there: \\
   - The ref vs alt alleles, \\
   - variant quality (QUAL column) \\
   - The per-sample genotype (GT) values.

Note on vcf fields
\begin{verbatim}
INFO: 
	DP = "Raw read depth"
FORMAT:
	GT = "Genotype”; 
	PL = "List of Phred-scaled genotype likelihoods“ (min is better) ; 
	DP = "# high-quality bases“ ; 
	SP = "Phred-scaled strand bias P-value“ ; 
	GQ = "Genotype Quality“
\end{verbatim}

\begin{question}
Looking at the three vcf files, how can we detect only somatic variants?
\end{question}
\begin{answer}
some commands to find somatic variant in the vcf file

## varscan
\begin{lstlisting}
grep SOMATIC variant_calling/varscan.snp.vcf 
\end{lstlisting}

## MuTecT
\begin{lstlisting}
grep -v REJECT variant_calling/mutect.vcf | grep -v "^#"
\end{lstlisting}

## Strelka
\begin{lstlisting}
grep -v "^#" variant_calling/strelka.vcf
\end{lstlisting}
\end{answer}


\newpage

\section{Variant Visualisation}

The Integrative Genomics Viewer (IGV) is an efficient visualization tool for interactive exploration of large genome datasets. 

Before jumping into IGV, we'll generate a track IGV can use to plot coverage:
TODO: Check igvtools works on command line

# Coverage Track
\begin{lstlisting}
for i in normal tumour
do
  igvtools count \
    -f min,max,mean \
    alignment/${i}/${i}.sorted.dup.recal.bam \
    alignment/${i}/${i}.sorted.dup.recal.bam.tdf \
    b37
done
\end{lstlisting}


Then:
 
   1. Open IGV \\
   2. Chose the reference genome corresponding to those use for alignment (b37) \\
   3. Load bam file \\
   4. Load vcf files

Explore/play with the data: \\ 
   -find germline variants \\
   -find somatic variants \\
   -Look around...

\newpage


%----------------------------------------------------------------------------------------
%	VARIANT ANNOTATION
%----------------------------------------------------------------------------------------

\section{Variant Annotation}

Following variant calling, we end up with a VCF file of genomic coordinates with the genotype(s) and quality information for each variant. By itself, this information is not much use to us unless there is a specific genomic location we are interested in. Generally, we next want to annotate these variants to determine whether they impact any genes and if so what is their level of impact (e.g. are they causing a premature stop codon gain or are they missense mutations).

The sections above have dealt with calling somatic variants from the first 10Mb of chromosome 4. This is important in finding variants that are unique to the tumour sample(s) and may have driven both tumour growth and/or metastasis. An important secondary question is whether the germline genome of the patient contains any variants that may have contributed to the development of the initial tumour through predisposing the patient to cancer. These variants \textit{may not} be captured by somatic variant analysis as their allele frequency may not change in the tumour genome compared with the normal.

For this section, we will use \textbf{all} variants from the first 60Mb of chromosome 5 produced using the GATK HaplotypeCaller variant caller on both the normal and tumour genomes to produce GVCF files which are fed into GATK GenotypeGVCFs to produce a merged VCF file. We will be using a pre-generated VCF file as we are primarily interested in the annotation of these variants rather than their generation. The annotation method we will use is called \textbf{Variant Effect Predictor} or VEP for short and is available from Ensembl here: \url{http://ensembl.org/info/docs/tools/vep/index.html}{http://ensembl.org/info/docs/tools/vep/index.html}.

\begin{steps}
Our pre-generated VCF file is located in the [TODO] folder. Lets have a quick look at the variants:
\begin{lstlisting}
less /[TODO]/SM_liverMets.merged.mrkdup.realn.chr5.60Mb.vcf.gz
\end{lstlisting}
\end{steps}

Notice how there are two genotype blocks at the end of each line for the normal (Blood) and tumour (liverMets) samples.

Let's now run VEP on this VCF file to annotate each variant with its impact(s) on the genome.

\begin{steps}
\begin{lstlisting}
/vep/variant_effect_predictor.pl -i [TODO]/SM_liverMets.merged.mrkdup.realn.chr5.60Mb.vcf.gz --vcf -o [TODO]/SM_liverMets.merged.mrkdup.realn.chr5.60Mb.vep.vcf --stats_file [TODO]/SM_liverMets.merged.mrkdup.realn.chr5.60Mb.vep.html --offline --fork 4 --no_progress --canonical --sift b --polyphen b --symbol --numbers --terms so --biotype --total_length --plugin LoF,human_ancestor_fa:false --fields Consequence,Codons,Amino_acids,Gene,SYMBOL,Feature,EXON,PolyPhen,SIFT,Protein_position,BIOTYPE,CANONICAL,Feature_type,cDNA_position,CDS_position,Existing_variation,DISTANCE,STRAND,CLIN_SIG,LoF_flags,LoF_filter,LoF,RadialSVM_score,RadialSVM_pred,LR_score,LR_pred,CADD_raw,CADD_phred,Reliability_index,HGVSc,HGVSp --fasta [TODO]/human_g1k_v37.fasta
\end{lstlisting}
\end{steps}

VEP will take approximately 10 minutes to run and once it is finished you will have a new VCF file with all of the information in the input file but with added annotations in the INFO block. VEP also produces an HTML report summarising the distribution and impact of variants identified.

\begin{steps}
Once VEP is done running, lets first look at the HTML report it produced with the following command:
\begin{lstlisting}
run [TODO]/SM_liverMets.merged.mrkdup.realn.chr5.60Mb.vep.html
\end{lstlisting}
\end{steps}

[TODO description of HTML]

\begin{steps}
Now lets look at the variant annotations that VEP has added to the VCF file by focussing on a single variant. Lets fetch one variant from the original VCF file and the annotated VCF file.
\begin{lstlisting}
zcat [TODO]/SM_liverMets.merged.mrkdup.realn.chr5.60Mb.vcf.gz | grep '^5\textbackslash t174106\textbackslash t'
grep '^5\textbackslash t174106\textbackslash t' [TODO]/SM_liverMets.merged.mrkdup.realn.chr5.60Mb.vep.vcf
\end{lstlisting}
\end{steps}

These commands give us the original variant:
5	174106	.	G	A	225.44	.	AC=2;AF=0.500;AN=4;BaseQRankSum=1.22;ClippingRankSum=0.811;DP=21;FS=0.000;GQ_MEAN=127.00;GQ_STDDEV=62.23;MLEAC=2;MLEAF=0.500;MQ=60.00;MQ0=0;MQRankSum=0.322;NCC=0;QD=10.74;ReadPosRankSum=0.377;SOR=0.446	GT:AD:DP:GQ:PL	0/1:7,6:13:99:171,0,208	0/1:5,3:8:83:83,0,145

and the same variant annotated is:
5	174106	.	G	A	225.44	.	AC=2;AF=0.500;AN=4;BaseQRankSum=1.22;ClippingRankSum=0.811;DP=21;FS=0.000;GQ_MEAN=127.00;GQ_STDDEV=62.23;MLEAC=2;MLEAF=0.500;MQ=60.00;MQ0=0;MQRankSum=0.322;NCC=0;QD=10.74;ReadPosRankSum=0.377;SOR=0.446;CSQ=missense_variant|cGg/cAg|R/Q|ENSG00000153404|PLEKHG4B|ENST00000283426|16/18|benign(0.033)|deleterious(0.04)|1076/1271|protein_coding|YES|Transcript|3277/11513|3227/3816|||1||||||||||||ENST00000283426.6:c.3227G>A|ENSP00000283426.6:p.Arg1076Gln,non_coding_transcript_exon_variant&non_coding_transcript_variant|||ENSG00000153404|PLEKHG4B|ENST00000504041|5/8||||retained_intron||Transcript|1106/2165||||1||||||||||||ENST00000504041.1:n.1106G>A|	GT:AD:DP:GQ:PL	0/1:7,6:13:99:171,0,208	0/1:5,3:8:83:83,0,145

You can see that all VEP has added is:
CSQ=missense_variant|cGg/cAg|R/Q|ENSG00000153404|PLEKHG4B|ENST00000283426|16/18|benign(0.033)|deleterious(0.04)|1076/1271|protein_coding|YES|Transcript|3277/11513|3227/3816|||1||||||||||||ENST00000283426.6:c.3227G>A|ENSP00000283426.6:p.Arg1076Gln,non_coding_transcript_exon_variant&non_coding_transcript_variant|||ENSG00000153404|PLEKHG4B|ENST00000504041|5/8||||retained_intron||Transcript|1106/2165||||1||||||||||||ENST00000504041.1:n.1106G>A|

This is further composed of two annotations for this variant:
missense_variant|cGg/cAg|R/Q|ENSG00000153404|PLEKHG4B|ENST00000283426|16/18|benign(0.033)|deleterious(0.04)|1076/1271|protein_coding|YES|Transcript|3277/11513|3227/3816|||1||||||||||||ENST00000283426.6:c.3227G>A|ENSP00000283426.6:p.Arg1076Gln

and

non_coding_transcript_exon_variant&non_coding_transcript_variant|||ENSG00000153404|PLEKHG4B|ENST00000504041|5/8||||retained_intron||Transcript|1106/2165||||1||||||||||||ENST00000504041.1:n.1106G>A|

The first of these is saying that this variant is a missense variant in the gene PLEKHG4B for the transcript ENST00000283426 and the second that it is also a non_coding_transcript_exon_variant in the transcript ENST00000504041.

%----------------------------------------------------------------------------------------
%	VARIANT FILTRATION
%----------------------------------------------------------------------------------------

\section{Variant Filtration}

We now have a VCF file where each variant has been annotated with its impact(s) on one or more genes. 

%----------------------------------------------------------------------------------------

\newpage

%----------------------------------------------------------------------------------------
%	REFERENCES
%----------------------------------------------------------------------------------------

\section{References}

%TODO Change to using BiBTeX
\begin{enumerate}
  \item Ju YS1, Lee WC, Shin JY, Lee S, Bleazard T, Won JK, Kim YT, Kim JI, Kang JH, Seo JS. A transforming KIF5B and RET gene fusion in lung adenocarcinoma revealed from whole-genome and transcriptome sequencing. Genome Res. 2012 Mar;22(3):436-45. 
\end{enumerate}

\section{Acknowledgements}
This tutorial is an adaptation of the one created by Louis letourneau \url[https://github.com/lletourn/Workshops/tree/ebiCancerWorkshop201407doc/01-SNVCalling.md]. I would like to thank and acknowledge Louis for this help and for sharing his material. The format of the tutorial has been inspired from Mar Gonzalez Porta. I also want to acknowledge Joel Fillon, Louis Letrouneau (again), Francois Lefebvre, Maxime Caron and Guillaume Bourque for the help in building these pipelines and working with all the various datasets.
